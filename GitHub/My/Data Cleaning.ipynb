{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb236c0-7caf-429c-8035-6042e2567252",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c5d68-8e95-46aa-8e22-83aebec54a31",
   "metadata": {
    "tags": []
   },
   "source": [
    "### String to Int | Delete $ (Strip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcad3c2-0583-47e0-9cad-91c609514b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove $ from Revenue column\n",
    "sales['Revenue'] = sales['Revenue'].str.strip('$')\n",
    "sales['Revenue'] = sales['Revenue'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c123e-8dc1-43bf-b483-5716fcf85f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that Revenue is now an integer\n",
    "assert sales['Revenue'].dtype == 'int'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263d9b19-bbf1-4457-bebc-c7067cff1c6f",
   "metadata": {},
   "source": [
    "## The assert statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9aaeefe-f2a7-4355-915b-f96ab72de5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will pass\n",
    "assert 1+1 == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1add2bfa-a581-45a3-907e-43c61e39b0a7",
   "metadata": {},
   "source": [
    "## Numeric or categorical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01dbc32-343d-4c16-9841-48aed9f3a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to categorical\n",
    "df[\"marriage_status\"] = df[\"marriage_status\"].astype('category')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6935800d-1984-4660-8310-1930dd517c6d",
   "metadata": {},
   "source": [
    "## Can future sign-ups exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a699a-d1d3-4674-ac99-bb3d730dfd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import date time\n",
    "import datetime as dt\n",
    "today_date = dt.date. today()\n",
    "user_signups[user_signups|'subscription_date'] > dt. date. today ()1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3f214-9e02-49d2-beaf-bd99dc52f25e",
   "metadata": {},
   "source": [
    "### DROP VALUES (TWO WAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5917d2c3-65b5-4671-836e-a5993c3a7128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop values using filtering\n",
    "movies = movies[movies['avg_rating'] ≤ 5]\n",
    "# Drop values using .drop()\n",
    "movies.drop (movies[movies['avg_rating'] > 5].index, inplace ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241d262-5238-4ef5-88fd-b47ee37ad345",
   "metadata": {},
   "source": [
    "## Check deleting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b86bb1-2618-41e8-9700-a3fc3377191c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assert results\n",
    "assert movies['avg_rating'].max() <="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e4aaff-cdf2-4a30-b16c-56bf7b8d365f",
   "metadata": {},
   "source": [
    "## Third Way - Replace Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af6e4e-6ad7-434d-b1a3-a2c6d142875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert avg_rating > 5 to 5\n",
    "movies.loc[movies['avg_rating'] ≥ 5, 'avg_rating'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18075ccb-971c-450b-927b-c6e67e923126",
   "metadata": {},
   "source": [
    "# Cleaning Date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbce388-fc5c-42e8-9990-d255f75c8f45",
   "metadata": {},
   "source": [
    "## Convert to Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddf565-2b54-4b5c-b9c5-84265ce12ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to date\n",
    "user_signupsI'subscription_date'] = pd.to_datetime(user_signups['subscription_date ']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fac9bb-d2c4-45af-ae37-934130c72bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "today = dt.date.today()\n",
    "\n",
    "# Drop the data\n",
    "# Drop values using filtering\n",
    "user_signups = user_signups[user_signups['subscription_date'] ≤ today_date]\n",
    "\n",
    "# Drop values using .drop()\n",
    "user_signups.drop(user_signups[user_signups['subscription_date'] > today_date].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311fc43-faf2-4811-a9ca-8eb7501f3634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop values using filtering\n",
    "user_signups.loc[user_signups['subscription_date'] > today_date, 'subscription_date'] = today_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32782493-9e02-447c-8a64-6c43a0d09121",
   "metadata": {},
   "source": [
    "## Duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee2b28-56f7-4601-b485-a8e1d2515e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get duplicates across all columns\n",
    "duplicates = height_weight.duplicated()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a786709-a965-4a4d-90f6-ec0f2ae50583",
   "metadata": {},
   "source": [
    "True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c4eeda-b499-4eb7-a6f1-5f6a11bd0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_weight['duplicates']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ec51b9-eab5-4096-886f-e3cd75d89145",
   "metadata": {},
   "source": [
    "### Check duplicated (3 cloumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778cb306-ddfe-4e1f-9c05-0d17ca731562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names to check for duplication\n",
    "column_names = ['first_name','last_name', 'address']\n",
    "duplicates = height_weight.duplicated(subset = column_names, keep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08e78a0-1df7-42d4-8190-d78a23f11901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output duplicate values\n",
    "height_weight[duplicates].sort_values(by = 'first_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65b562e-91ec-45f2-b2e9-387f1d2c1499",
   "metadata": {},
   "source": [
    "### Drop complete duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe24975-ed89-4b00-ab6b-5c7295f5d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "height_weight.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d0289e-ee26-4876-861e-8dce84964dff",
   "metadata": {},
   "source": [
    "### A statistical measure to combine each set of duplicated values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e40e1-8a0a-476e-98a0-79abe9df856c",
   "metadata": {},
   "source": [
    "#### The groupby and agg() methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9cf829-35cb-4af1-aa9b-795f1108ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by column names and produce statistical summaries\n",
    "column_names = ['first_name'|'last_name', 'address']\n",
    "summaries = {'height': 'max', 'weight': 'mean'}\n",
    "height_weight = height_weight.groupby(by = column_names).agg(summaries).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe961e-7821-4423-995e-b62c544a0ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure aggregation is done\n",
    "duplicates = height_weight.duplicated(subset = column_names, keep = False)\n",
    "height_weight[duplicates].sort_values(by = 'first_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b32957-d492-4f6c-909c-92e8cf1eb062",
   "metadata": {},
   "source": [
    "# Membership constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063b4e3-15aa-4829-84b0-2305332afb68",
   "metadata": {},
   "source": [
    "### Finding inconsistent categories (not in category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcce043-3497-43e8-8227-25e32321aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inconsistent_categories = set(study_data['blood_type').difference(categories['blood_type'])\n",
    "print(inconsistent_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73440492-6931-4410-a270-97b927c491db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and print rows with inconsistent categories\n",
    "inconsistent_rows = study_data['blood_type'].isin(inconsistent_categories)\n",
    "study_data[inconsistent_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24911c72-03cf-409c-84cb-09540ca6a08c",
   "metadata": {},
   "source": [
    "### Dropping inconsistent categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d9395-a891-4945-94c9-5e30d0b67b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop inconsistent categories and get consistent data only\n",
    "consistent_data = study_data[~inconsistent_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd350de-6be0-4fdd-bb29-96edf1fc34a9",
   "metadata": {},
   "source": [
    "### Value consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2089db7e-deb8-4ef8-9ff2-937cc229f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalize\n",
    "marriage_status[marriage_status'] = marriage_status[ 'marriage_status'].str.upper ()\n",
    "marriage_status['marriage_status'].value_counts()\n",
    "# UNMARRIED MARRIED\n",
    "\n",
    "# Lowercase\n",
    "marriage_status['marriage_status'] = marriage_status[ 'marriage_status '].str.lower()\n",
    "marriage_status['marriage_status'].value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebce071-bb91-4864-91f8-bcf912ce539d",
   "metadata": {},
   "source": [
    "### Trailing spaces: married , \" married', 'unmarried ', \" unmarried'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ebe41-ed79-4a71-87c6-0378f936b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get marriage status column\n",
    "marriage_status = demographics['marriage_status']\n",
    "marriage_status.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b45b2-b343-492a-b859-ae53c8a680ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip all spaces\n",
    "demographics = demographics['marriage_status'].str.strip()\n",
    "demographics| 'marriage_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f5c8d9-1c2a-4387-9acd-864b7949c095",
   "metadata": {},
   "source": [
    "### CREATE CATEGORY COLUMN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57630144-4a76-45d8-994e-03c78e286023",
   "metadata": {},
   "source": [
    "### Create categories out of data: income_group column from income column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b20a430-4875-433f-92cb-d3142dbfa12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using cut) - create category ranges and names\n",
    "ranges = [0,200000,500000,пр.inf]\n",
    "group_names = ['0-200K', '200K-500K', '500K+']\n",
    "# Create income group column\n",
    "demographics['income_group'1 = pd.cut(demographics['household_income'], bins=ranges,\n",
    "labels=group_names)\n",
    "demographicsIl'income_group', 'household_income'11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c181a6eb-46aa-49e9-9b55-a8d7e5902cec",
   "metadata": {},
   "source": [
    "### Map categories to fewer ones: reducing categories in categorical column. operating_system column is: 'Microsoft', 'Macos', 'IOS', 'Android', 'Linux' operating_system column should become: 'DesktopS', 'Mobile0S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0791ab2-9735-4cbb-83d9-371fd12c7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping dictionary and replace\n",
    "mapping = {'Microsoft': 'Desktop0S', 'MacOS': 'Desktop0S', 'Linux': 'Desktop0S',\n",
    "'IOS': 'MobileOS', 'Android':'Mobile0S'}\n",
    "devices['operating_system'] = devices['operating_system'].replace (mapping)\n",
    "devices['operating_system'].unique()\n",
    "array(I'Desktop0S', 'Mobile0S'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f679e20-222c-45fc-828d-706d9186333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower() \n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "\n",
    "# Remove white spaces from `dest_size`\n",
    "airlines['dest_size'] = airlines['dest_size'].str.strip()\n",
    "\n",
    "# Verify changes have been effected\n",
    "print(airlines['dest_size'].unique())\n",
    "print(airlines['dest_region'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe170b23-cd92-45e7-a75f-d0c01e08ffa6",
   "metadata": {},
   "source": [
    "### example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2b7ba-fb05-4610-9945-2f88bfbd7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, \n",
    "                               labels = label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
    "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)\n",
    "print(airlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a367e2-76a9-40b6-a3fa-1e8d4a61ebb4",
   "metadata": {},
   "source": [
    "0       115.0\n",
    "1       135.0\n",
    "2        70.0\n",
    "3       190.0\n",
    "4       559.0\n",
    "        ...  \n",
    "2804    280.0\n",
    "2805    165.0\n",
    "2806     92.0\n",
    "2807     95.0\n",
    "2808    220.0\n",
    "Name: wait_min, Length: 2477, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1618a7-e48f-4d72-b452-1f55df516308",
   "metadata": {},
   "source": [
    "        id        day        airline        destination    dest_region  ...     cleanliness         safety        satisfaction  wait_type day_week\n",
    "0     1351    Tuesday    UNITED INTL             KANSAI           Asia  ...           Clean        Neutral      Very satisfied     medium  weekday\n",
    "1      373     Friday         ALASKA  SAN JOSE DEL CABO  Canada/Mexico  ...           Clean      Very safe      Very satisfied     medium  weekday\n",
    "2     2820   Thursday          DELTA        LOS ANGELES        West US  ...         Average  Somewhat safe             Neutral     medium  weekday\n",
    "3     1157    Tuesday      SOUTHWEST        LOS ANGELES        West US  ...           Clean      Very safe  Somewhat satsified       long  weekday\n",
    "4     2992  Wednesday       AMERICAN              MIAMI        East US  ...  Somewhat clean      Very safe  Somewhat satsified       long  weekday\n",
    "...    ...        ...            ...                ...            ...  ...             ...            ...                 ...        ...      ...\n",
    "2804  1475    Tuesday         ALASKA       NEW YORK-JFK        East US  ...  Somewhat clean        Neutral  Somewhat satsified       long  weekday\n",
    "2805  2222   Thursday      SOUTHWEST            PHOENIX        West US  ...           Clean      Very safe      Very satisfied     medium  weekday\n",
    "2806  2684     Friday         UNITED            ORLANDO        East US  ...           Clean      Very safe      Very satisfied     medium  weekday\n",
    "2807  2549    Tuesday        JETBLUE         LONG BEACH        West US  ...           Clean  Somewhat safe      Very satisfied     medium  weekday\n",
    "2808  2162   Saturday  CHINA EASTERN            QINGDAO           Asia  ...           Clean      Very safe  Somewhat satsified       long  weekend\n",
    "\n",
    "[2477 rows x 14 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed16d5-1fd2-49f4-92b2-accf79115479",
   "metadata": {},
   "source": [
    "### Fixing the phone number column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb63b22-ac26-4538-94ce-a8d6ac9accab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"+\" with \"00\"\n",
    "phonesI\"Phone number\"] = phones[ \"Phone number\"].str.replace(\"+\", \"00\")\n",
    "phonesI\"Phone number\"] = phones[ \"Phone number\"].str.replace(\"-\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed1f23-7cd4-4da0-829c-ed538aed91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace phone numbers with lower than 10 digits to NaN\n",
    "digits = phones['Phone number'].str.len()\n",
    "phones.loc[digits < 10, \"Phone number\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8dd282-a241-421c-aa6f-d7cf9a2020be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find length of each row in Phone number column\n",
    "sanity_check = phone['Phone number'].str.len()\n",
    "# Assert minmum phone number length is 10\n",
    "assert sanity_check.min) >= 10\n",
    "# Assert all numbers do not have\n",
    "\"+\" or \"_\"\n",
    "assert phone['Phone number'].str.contains(\"+|-\").any() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e1ef5-b540-4830-bcbb-444fc082464b",
   "metadata": {},
   "source": [
    "IF phones\n",
    "\n",
    "Olga Robinson +(01706) -25891\n",
    "1\n",
    "Justina Kim\n",
    "+0500-571437\n",
    "2\n",
    "Tamekah Henson\n",
    "+0800-1111\n",
    "3\n",
    "Miranda Solis\n",
    "+07058-879063\n",
    "4\n",
    "Caldwell Gilliam +(016977)-8424"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5354167-ecee-4076-88a7-6b2b9d117f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace letters with nothing\n",
    "phones['Phone number'] = phones['Phone number'].str.replace(r'ID+', '')\n",
    "phones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39f11b2-2555-4a8b-8dac-acfa38b775ad",
   "metadata": {},
   "source": [
    "### Example Dr, Mr, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5020e5e-9c0d-4a64-906d-33adaf106ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"Dr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Dr.\", \"\")\n",
    "\n",
    "# Replace \"Mr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Mr.\", \"\")\n",
    "\n",
    "# Replace \"Miss\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Miss\", \"\")\n",
    "\n",
    "# Replace \"Ms.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Ms.\", \"\")\n",
    "\n",
    "# Assert that full_name has no honorifics\n",
    "assert airlines['full_name'].str.contains('Ms.|Mr.|Miss|Dr.').any() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c053296-4ec1-4869-82fc-abd8661f7d7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Uniformity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3adec1-d16e-4410-b68d-503b0e8a5844",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542df7da-5f4e-4505-bb76-67fecb0f2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Create scatter plot\n",
    "plt.scatter(× = 'Date', y = 'Temperature', data = temperatures)\n",
    "# Create title, xlabel and ylabel\n",
    "plt.title('Temperature in Celsius March 2019 - NYC')\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Temperature in Celsius')\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d655a2-b874-49bb-878a-f8913e015dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_fah = temperatures.Loc[temperatures['Temperature'] > 40, 'Temperature']\n",
    "temp_cels = (temp_fah - 32) * (5/9)\n",
    "temperatures.loc[temperatures['Temperature'] > 40, 'Temperature'] = temp_cels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a92a8-81e1-40ca-906e-c0e738aa16ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert conversion is correct\n",
    "assert temperatures['Temperature'].max() < 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede35ac7-b47e-4096-8ee7-4ffe0f6eb7f8",
   "metadata": {},
   "source": [
    "## Birth Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44233dad-bd0a-4e10-896f-979b12a18609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will work!\n",
    "birthdays['Birthday'] = pd.to_datetime(birthdays['Birthday'],\n",
    "# Attempt to infer format of each date\n",
    "infer_datetime_format=True,\n",
    "# Return NA for rows where conversion failed\n",
    "errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69beacf8-2eda-4773-a9c0-a197484c529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthdays['Birthday'] = birthdays['Birthday'].dt.strftime (\"%d-%m-%Y\"]\n",
    "birthdays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d2fec9-01bc-45cd-98a8-2d4f1548e1dd",
   "metadata": {},
   "source": [
    "## Money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4c2d6-8c49-4b73-a4b1-368844d4244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find values of acct_cur that are equal to 'euro'\n",
    "acct_eu = banking['acct_cur'] == 'euro'\n",
    "\n",
    "# Convert acct_amount where it is in euro to dollars\n",
    "banking.loc[acct_eu, 'acct_amount'] = banking.loc[acct_eu, 'acct_amount'] * 1.1 \n",
    "\n",
    "# Unify acct_cur column by changing 'euro' values to 'dollar'\n",
    "banking.loc[acct_eu, 'acct_cur'] = 'dollar'\n",
    "\n",
    "# Assert that only dollar currency remains\n",
    "assert banking['acct_cur'].unique() == 'dollar'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05268254-8128-4724-a8b9-4b1bb3b4cc64",
   "metadata": {},
   "source": [
    "# Cross field validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63291800-c356-4713-ac54-72106f6627e5",
   "metadata": {},
   "source": [
    "### Check age and date of birth from 2 datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015b8db5-1221-4ffd-b7bf-01d84b7189a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime and get today's date\n",
    "users['Birthday'] = pd.to_datetime(users['Birthday'])\n",
    "today = dt.date.today()\n",
    "# For each row in the Birthday column, calculate year difference\n",
    "age_manual = today.year - users['Birthday'].dt.year\n",
    "# Find instances where ages match\n",
    "age_equ = age_manual == users['Age']\n",
    "# Find and filter out rows with inconsistent age\n",
    "inconsistent_age = users[~age_equ]\n",
    "consistent_age = users[age_equ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2702963a-74b5-4852-95fc-1fadea0e5c28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check total sum from 2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220169ab-5c0d-4a47-978f-86434a5c65f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store fund columns to sum against\n",
    "fund_columns = ['fund_A', 'fund_B', 'fund_C', 'fund_D']\n",
    "\n",
    "# Find rows where fund_columns row sum == inv_amount\n",
    "inv_equ = banking[fund_columns].sum(axis = 1) == banking['inv_amount']\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "consistent_inv = banking[inv_equ]\n",
    "inconsistent_inv = banking[~inv_equ]\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "print(\"Number of inconsistent investments: \", inconsistent_inv.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77286a-1593-4c62-9b7f-6147c36b2c7c",
   "metadata": {},
   "source": [
    "banking\n",
    "Out[1]:\n",
    "\n",
    "     cust_id birth_date  age  acct_amount  inv_amount  ...   fund_B   fund_C   fund_D  account_opened last_transaction\n",
    "0   870A9281 1962-06-09   62     63523.31       51295  ...   4138.0   1420.0  15632.0        02-09-18         22-02-19\n",
    "1   166B05B0 1962-12-16   62     38175.46       15050  ...    938.0   6696.0   2421.0        28-02-19         31-10-18\n",
    "2   BFC13E88 1990-09-12   34     59863.77       24567  ...   4590.0   8469.0   1185.0        25-04-18         02-04-18\n",
    "3   F2158F66 1985-11-03   39     84132.10       23712  ...    492.0   6482.0  12830.0        07-11-17         08-11-18\n",
    "4   7A73F334 1990-05-17   40    120512.00       93230  ...  51281.0  13434.0  18383.0        14-05-18         19-07-18\n",
    "..       ...        ...  ...          ...         ...  ...      ...      ...      ...             ...              ...\n",
    "95  CA507BA1 1974-08-10   50     12209.84        7515  ...    931.0   1451.0   4943.0        26-05-18         11-09-19\n",
    "96  B99CD662 1989-12-12   35     92838.44       49089  ...   7892.0  31486.0   7258.0        04-05-17         12-03-19\n",
    "97  13770971 1984-11-29   40     92750.87       27962  ...   7547.0   8486.0   8577.0        16-08-17         24-04-19\n",
    "98  93E78DA3 1969-12-14   55     41942.23       29662  ...  11174.0  11650.0   5080.0        09-10-17         15-04-18\n",
    "99  AC91D689 1993-05-18   31     99490.61       32149  ...  17918.0   6714.0   5333.0        01-08-17         04-08-19\n",
    "\n",
    "[100 rows x 11 columns\n",
    "\n",
    "Number of inconsistent investments:  8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b5941-ff31-411c-903a-0c504094bc5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check date, age, and change if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280d577b-a4d5-46e4-a972-67ebba31a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store today's date and find ages\n",
    "today = dt.date.today()\n",
    "ages_manual = today.year - banking['birth_date'].dt.year\n",
    "\n",
    "# Find rows where age column == ages_manual\n",
    "age_equ = banking['age'] == ages_manual\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "consistent_ages = banking[age_equ]\n",
    "inconsistent_ages = banking[~age_equ]\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "print(\"Number of inconsistent ages: \", inconsistent_ages.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a138ee-b515-45b5-bca5-86aa85d721cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc70e42-50b9-417c-b568-fdb3a3733530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# false true of the missing values\n",
    "df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e555e-8149-4b6e-87dd-f3046b405192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of the missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d1479-7fff-4f18-bcbb-a31ac84261d1",
   "metadata": {},
   "source": [
    "## Useful package for visualizing and understanding missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a2ab9-acf2-4034-8923-d1b48dadfbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno import matplotlib.pyplot as plt\n",
    "# Visualize missingness\n",
    "msno.matrix(airquality)\n",
    "plt. show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34c2ba-5448-4db8-acf0-dd9d2187fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a3266-f3fd-4615-b554-261863aad464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate missing and complete values aside\n",
    "missing = airqualitylairquality['C02'].isna()]\n",
    "complete = airquality[~airquality['C02'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01d9d2-50fc-4af1-8f53-3737fcc72c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete.describe()\n",
    "missing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc779471-9be8-4d52-a96c-a48b18e3a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort banking by age and visualize\n",
    "banking_sorted = banking.sort_values('age')\n",
    "msno.matrix(banking_sorted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba24ce-2d0c-416e-9bd4-1ac0b05ecc88",
   "metadata": {},
   "source": [
    "### Dropping missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5a21a-8f88-4279-a7a0-bf1ee924f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "airquality_dropped = airquality.dropna(subset = ['CO2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a761a1-5e5c-4c1e-b560-dd5a5ab8cc07",
   "metadata": {},
   "source": [
    "### Replacing with statistical measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880bec1d-5db0-43e3-8450-149f9bcd038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_mean = airquality['C02'].mean()\n",
    "airquality_imputed = airquality.fillna({'C02': co2_mean})\n",
    "airquality_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e51ee-9bd7-4105-b593-c77ba96d466a",
   "metadata": {},
   "source": [
    "# Comparing strings\n",
    "## Simple string comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc7b116-faba-40c6-86d3-c5867d55704a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets us compare between two strings (0-100) 100 - match (means 'the same')\n",
    "from thefuzz import fuzz\n",
    "# Compare reeding vs reading\n",
    "fuzz.WRatio('Reeding', 'Reading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b12842-e64c-4189-a1df-d224d76fa226",
   "metadata": {},
   "outputs": [],
   "source": [
    "What if we have a lot of categories with the similar words ('Cal', 'Cali', 'California', etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd33fa70-87d8-4fa2-b7c8-167e3eaed83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each correct category\n",
    "for state in categories['state']:\n",
    "# Find potential matches in states with typoes\n",
    "matches = process.extract(state, survey['state'], limit = survey.shape[0])\n",
    "# For each potential match match\n",
    "for potential_match in matches:\n",
    "# If high similarity score\n",
    "if potential_match[1] >= 80:\n",
    "# Replace typo with correct category\n",
    "survey.loc[survey['state'] == potential_match[0], 'state'] = state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89310fe9-8a55-4224-b334-38bba9114911",
   "metadata": {
    "tags": []
   },
   "source": [
    "### example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd71da8-aa7c-460e-ac4a-7033981d74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import process from thefuzz\n",
    "from thefuzz import process\n",
    "\n",
    "# Store the unique values of cuisine_type in unique_types\n",
    "unique_types = restaurants['cuisine_type'].unique()\n",
    "\n",
    "# Calculate similarity of 'asian' to all values of unique_types\n",
    "print(process.extract('asian', unique_types, limit = len(unique_types)))\n",
    "\n",
    "# Calculate similarity of 'american' to all values of unique_types\n",
    "print(process.extract('american', unique_types, limit = len(unique_types)))\n",
    "\n",
    "# Calculate similarity of 'italian' to all values of unique_types\n",
    "print(process.extract('italian', unique_types, limit = len(unique_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c96d42c-a4e2-4035-b87e-1bf4f9d65e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of matches, comparing 'italian' with the cuisine_type column\n",
    "matches = process.extract('italian', restaurants['cuisine_type'], limit=len(restaurants.cuisine_type))\n",
    "\n",
    "# Inspect the first 5 matches\n",
    "print(matches[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e25b13-ddd6-4aea-8ab0-8d8f96656a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the list of matches to italian\n",
    "for match in matches:\n",
    "  # Check whether the similarity score is greater than or equal to 80\n",
    "  if match[1] >= 80:\n",
    "    # Select all rows where the cuisine_type is spelled this way, and set them to the correct cuisine\n",
    "    restaurants.loc[restaurants['cuisine_type'] == match[0]] = 'italian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9669f76a-a1ee-4a8a-9d6a-090c6c7adde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through categories\n",
    "for cuisine in categories:  \n",
    "  # Create a list of matches, comparing cuisine with the cuisine_type column\n",
    "  matches = process.extract(cuisine, restaurants['cuisine_type'], limit=len(restaurants.cuisine_type))\n",
    "\n",
    "  # Iterate through the list of matches\n",
    "  for match in matches:\n",
    "     # Check whether the similarity score is greater than or equal to 80\n",
    "    if match[1] >= 80:\n",
    "      # If it is, select all rows where the cuisine_type is spelled this way, and set them to the correct cuisine\n",
    "      restaurants.loc[restaurants['cuisine_type'] == match[0]] = cuisine\n",
    "      \n",
    "# Inspect the final result\n",
    "print(restaurants['cuisine_type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97310f9-67ac-4c68-b893-64c32512aa06",
   "metadata": {},
   "source": [
    "# Generating pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd20c064-4796-4773-a784-1935c9aef932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import recordlinkage\n",
    "import recordlinkage\n",
    "# Create indexing object\n",
    "indexer = recordlinkage.Index()\n",
    "# Generate pairs blocked on state\n",
    "indexer.block('state')\n",
    "pairs = indexer.index(census_A, census_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8682ef8f-c6e8-439c-afae-c9ddff382208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Compare object\n",
    "compare_cl = recordlinkage.Compare()\n",
    "# Find exact matches for pairs of date_of_birth and state\n",
    "compare_cl.exact('date_of_birth', 'date_of_birth', label='date_of_birth')\n",
    "compare_cl.exact('state', 'state' , label=' state')\n",
    "# Find similar matches for pairs of surname and address_1 using string similarity\n",
    "compare_cl.string('surname', 'surname', threshold=0.85, label='surname')\n",
    "compare_cl.string('address_1', 'address_1', threshold=0.85, label='address_1')\n",
    "# Find matches\n",
    "potential_matches = compare_cl.compute(pairs, census_A, census_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82705185-f997-4613-b37e-7c6b7e2f8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate matches with matching values for 3 or more columns\n",
    "matches = potential_matches[potential_matches.sum(axis = 1) >= 3]\n",
    "# Get index for matching census_B rows only\n",
    "duplicate_rows = matches.index.get_level_values(1)\n",
    "# Finding new rows in census_B\n",
    "census_B_new = census_B[~census_B.index.isin(duplicate_rows)]\n",
    "# Link the DataFrames!\n",
    "full_census = census_A.append(census_B_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac9dff0-a2ff-4206-9f41-4e6a2568b1ac",
   "metadata": {},
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53299ebb-a6d7-4379-9301-cb713d934033",
   "metadata": {},
   "source": [
    "# Iterating over iterables: next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f4f97054-ab7d-4495-a076-e4134ef7c331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'Da'\n",
    "it = iter (word)\n",
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0fd7eeeb-b06e-41f2-9c26-8ee3db13a22c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print(*it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18457d-2879-4b4c-851b-6c5fe1888cb5",
   "metadata": {},
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b278ed62-d303-4f2a-8b52-8278670cdd65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jay garrick\n",
      "barry allen\n",
      "wally west\n",
      "bart allen\n",
      "jay garrick\n",
      "barry allen\n",
      "wally west\n",
      "bart allen\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: flash\n",
    "flash = ['jay garrick', 'barry allen', 'wally west', 'bart allen']\n",
    "\n",
    "# Print each list item in flash using a for loop\n",
    "for person in flash:\n",
    "    print(person)\n",
    "\n",
    "# Create an iterator for flash: superhero\n",
    "superhero = iter(flash)\n",
    "\n",
    "# Print each item from the iterator\n",
    "print(next(superhero))\n",
    "print(next(superhero))\n",
    "print(next(superhero))\n",
    "print(next(superhero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "71fbe215-2bbd-417c-94a6-283058cfc639",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Create an iterator for range(3): small_value\n",
    "small_value = iter(range(3))\n",
    "\n",
    "# Print the values in small_value\n",
    "print(next(small_value))\n",
    "print(next(small_value))\n",
    "print(next(small_value))\n",
    "\n",
    "# Loop over range(3) and print the values\n",
    "for num in range(3):\n",
    "    print(num)\n",
    "\n",
    "# Create an iterator for range(10 ** 100): googol\n",
    "googol = iter(range(10 ** 100))\n",
    "\n",
    "# Print the first 5 values from googol\n",
    "print(next(googol))\n",
    "print(next(googol))\n",
    "print(next(googol))\n",
    "print(next(googol))\n",
    "print(next(googol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfdffff-f192-4753-ac59-cf5e8ce2c8fd",
   "metadata": {},
   "source": [
    "## enumerate and unpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6a162773-45da-42cc-96d3-94a1d56c985c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 hawkeye\n",
      "1 iron man\n",
      "2 thor\n",
      "3 quicksilver\n"
     ]
    }
   ],
   "source": [
    "avengers = ['hawkeye', 'iron man', 'thor', 'quicksilver']\n",
    "for index, value in enumerate(avengers):\n",
    "    print(index, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3485041f-c379-4100-9c8f-75d8edbb16f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 hawkeye\n",
      "11 iron man\n",
      "12 thor\n",
      "13 quicksilver\n"
     ]
    }
   ],
   "source": [
    "avengers = ['hawkeye', 'iron man', 'thor', 'quicksilver']\n",
    "for index, value in enumerate(avengers, start = 10):\n",
    "    print(index, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268e289c-aeb3-4f7f-b057-906bf247c58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'charles xavier'), (1, 'bobby drake'), (2, 'kurt wagner'), (3, 'max eisenhardt'), (4, 'kitty pryde')]\n",
      "0 charles xavier\n",
      "1 bobby drake\n",
      "2 kurt wagner\n",
      "3 max eisenhardt\n",
      "4 kitty pryde\n",
      "1 charles xavier\n",
      "2 bobby drake\n",
      "3 kurt wagner\n",
      "4 max eisenhardt\n",
      "5 kitty pryde\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: mutants\n",
    "mutants = ['charles xavier', \n",
    "            'bobby drake', \n",
    "            'kurt wagner', \n",
    "            'max eisenhardt', \n",
    "            'kitty pryde']\n",
    "\n",
    "# Create a list of tuples: mutant_list\n",
    "mutant_list = list(enumerate(mutants))\n",
    "\n",
    "# Print the list of tuples\n",
    "print(mutant_list)\n",
    "\n",
    "# Unpack and print the tuple pairs\n",
    "for index1, value1 in enumerate(mutants):\n",
    "    print(index1, value1)\n",
    "\n",
    "# Change the start index\n",
    "for index2, value2 in enumerate(mutants, start=1):\n",
    "    print(index2, value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1bf559-4f4b-456d-8915-8836c2bca72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of tuples: mutant_data\n",
    "mutant_data = list(zip(mutants, aliases, powers))\n",
    "\n",
    "# Print the list of tuples\n",
    "print(mutant_data)\n",
    "\n",
    "# Create a zip object using the three lists: mutant_zip\n",
    "mutant_zip = zip(mutants, aliases, powers)\n",
    "\n",
    "# Print the zip object\n",
    "print(mutant_zip)\n",
    "\n",
    "# Unpack the zip object and print the tuple values\n",
    "for value1, value2, value3 in mutant_zip:\n",
    "    print(value1, value2, value3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f836434-4ae3-43ef-b78f-05ad9496d9af",
   "metadata": {},
   "source": [
    "# Using iterators to load large files into memory (in chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8084474-0e72-467b-b913-e2880911c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterating over data \n",
    "import pandas as pd\n",
    "result = ［］\n",
    "for chunk in pd.read_csv('data.csv', chunksize=1000):\n",
    "result.append(sum(chunk['x']))\n",
    "total = sum(result)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcdec29-4e5f-4d13-ae82-08fd2f61c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "total = 0\n",
    "for chunk in pd.read_csv('data.csv', chunksize=1000):\n",
    "total += sum(chunk['x'])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f10d4-2cc7-4f3c-bfc2-8a8983c1c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary: counts_dict\n",
    "counts_dict = {}\n",
    "\n",
    "# Iterate over the file chunk by chunk\n",
    "for chunk in pd.read_csv('tweets.csv', chunksize=10):\n",
    "\n",
    "    # Iterate over the column in DataFrame\n",
    "    for entry in chunk['lang']:\n",
    "        if entry in counts_dict.keys():\n",
    "            counts_dict[entry] += 1\n",
    "        else:\n",
    "            counts_dict[entry] = 1\n",
    "\n",
    "# Print the populated dictionary\n",
    "print(counts_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba892a6a-5f51-487a-81ef-e6ebf53bdb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(csv_file, c_size, colname):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "    \n",
    "    # Initialize an empty dictionary: counts_dict\n",
    "    counts_dict = {}\n",
    "\n",
    "    # Iterate over the file chunk by chunk\n",
    "    for chunk in pd.read_csv(csv_file, chunksize=c_size):\n",
    "\n",
    "        # Iterate over the column in DataFrame\n",
    "        for entry in chunk[colname]:\n",
    "            if entry in counts_dict.keys():\n",
    "                counts_dict[entry] += 1\n",
    "            else:\n",
    "                counts_dict[entry] = 1\n",
    "\n",
    "    # Return counts_dict\n",
    "    return counts_dict\n",
    "\n",
    "# Call count_entries(): result_counts\n",
    "result_counts = count_entries('tweets.csv', 10, 'lang')\n",
    "\n",
    "# Print result_counts\n",
    "print(result_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c0712-077c-4a14-802e-e2734b0a8e18",
   "metadata": {},
   "source": [
    "# A list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "336dbf2b-3929-44a3-8b2a-fdffa013034b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 9, 22, 4, 17]\n"
     ]
    }
   ],
   "source": [
    "nums = [12, 8, 21, 3, 16]\n",
    "new_nums = [num + 1 for num in nums]\n",
    "print (new_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf2c8022-533c-425e-9567-4d879325c9b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "result = [num for num in range(11)]\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa6f9cf4-4eef-4442-b4bf-98eee78992fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 6), (0, 7), (1, 6), (1, 7)]\n"
     ]
    }
   ],
   "source": [
    "pairs_2 = [(num1, num2) for num1 in range(0, 2) for num2 in range(6, 8)]\n",
    "print (pairs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc20bc0-590d-4a1d-96de-07f16cddb1e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Create a 5 x 5 matrix using a list of lists: matrix\n",
    "matrix = [[col for col in range(5)] for row in range(5)]\n",
    "\n",
    "# Print the matrix\n",
    "for row in matrix:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80646f6f-6cab-4481-8240-6c8365b17ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 16, 36, 64]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conditionals on the iterable\n",
    "[num ** 2 for num in range(10) if num % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec4ce83d-8963-4394-a11f-65198c401a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 4, 0, 16, 0, 36, 0, 64, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conditionals on the output expression\n",
    "[num ** 2 if num % 2 == 0 else 0 for num in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae834dd-5af2-4537-a48a-7da2ec37d57c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: -1, 2: -2, 3: -3, 4: -4, 5: -5, 6: -6, 7: -7, 8: -8}\n"
     ]
    }
   ],
   "source": [
    "pos_neg = {num: -num for num in range(9)}\n",
    "print(pos_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c6d1dba-ed12-4de0-9e61-2f4ed2a230f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['samwise', 'aragorn', 'legolas', 'boromir']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# Create list comprehension: new_fellowship\n",
    "new_fellowship = [member for member in fellowship if len(member) >= 7]\n",
    "\n",
    "# Print the new list\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d285e1c-edf6-4e4e-9b5d-c136d3c780f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# Create list comprehension: new_fellowship\n",
    "new_fellowship = [member if len(member) >=7 else '' for member in fellowship]\n",
    "\n",
    "# Print the new list\n",
    "print(new_fellowship)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dd0181b-0eee-4a7c-8ca5-0cf72c365f68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frodo': 5, 'samwise': 7, 'merry': 5, 'aragorn': 7, 'legolas': 7, 'boromir': 7, 'gimli': 5}\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# Create dict comprehension: new_fellowship\n",
    "new_fellowship = { member:len(member) for member in fellowship }\n",
    "\n",
    "# Print the new dictionary\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92955e7e-ab72-4ee7-b562-faa058c382e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Lazy valuations\n",
    "result = (num for num in range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc3f7b19-6758-4400-b3b9-4da09ecabc48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    " print (next(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f917cdb-6f31-441d-b57c-aaa80af42354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 1 (4293202636.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[31], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    i = 0\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 1\n"
     ]
    }
   ],
   "source": [
    "def num_sequence(n) :\n",
    "# Generate values from 0 to n.\n",
    "i = 0\n",
    "while i < n:\n",
    "yield i \n",
    "i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1e9b22d-5731-4c8a-aea6-4ce542996e10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings\n",
    "lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']\n",
    "\n",
    "# Define generator function get_lengths\n",
    "def get_lengths(input_list):\n",
    "    \"\"\"Generator function that yields the\n",
    "    length of the strings in input_list.\"\"\"\n",
    "\n",
    "    # Yield the length of a string\n",
    "    for person in input_list:\n",
    "        yield len(person)\n",
    "\n",
    "# Print the values generated by get_lengths()\n",
    "for value in get_lengths(lannister):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c77b934-8b17-4238-846b-97b8c233b68e",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e2eeb-f094-4f00-aed4-a087c8a12181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the created_at column from df: tweet_time\n",
    "tweet_time = df['created_at']\n",
    "\n",
    "# Extract the clock time: tweet_clock_time\n",
    "tweet_clock_time = [entry[11:19] for entry in tweet_time]\n",
    "\n",
    "# Print the extracted times\n",
    "print(tweet_clock_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ddf099-36e0-46db-bee9-19d694283dc9",
   "metadata": {},
   "source": [
    "['23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:19', '23:40:18', '23:40:18', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d1b06e7-48c1-439b-8437-b7041b2c9eff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract the created_at column from df: tweet_time\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tweet_time \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Extract the clock time: tweet_clock_time\u001b[39;00m\n\u001b[1;32m      5\u001b[0m tweet_clock_time \u001b[38;5;241m=\u001b[39m [entry[\u001b[38;5;241m11\u001b[39m:\u001b[38;5;241m19\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m tweet_time \u001b[38;5;28;01mif\u001b[39;00m entry[\u001b[38;5;241m17\u001b[39m:\u001b[38;5;241m19\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m19\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract the created_at column from df: tweet_time\n",
    "tweet_time = df['created_at']\n",
    "\n",
    "# Extract the clock time: tweet_clock_time\n",
    "tweet_clock_time = [entry[11:19] for entry in tweet_time if entry[17:19] == '19']\n",
    "\n",
    "# Print the extracted times\n",
    "print(tweet_clock_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f448d-9b89-4bd7-b42a-ddda462a7832",
   "metadata": {},
   "source": [
    "  ['23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398cf5e5-f294-4571-a0ff-5af75729f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists2dict()\n",
    "def lists2dict(list1, list2):\n",
    "    \"\"\"Return a dictionary where list1 provides\n",
    "    the keys and list2 provides the values.\"\"\"\n",
    "\n",
    "    # Zip lists: zipped_lists\n",
    "    zipped_lists = zip(list1, list2)\n",
    "\n",
    "    # Create a dictionary: rs_dict\n",
    "    rs_dict = dict(zipped_lists)\n",
    "\n",
    "    # Return the dictionary\n",
    "    return rs_dict\n",
    "\n",
    "# Call lists2dict: rs_fxn\n",
    "rs_fxn = lists2dict(feature_names,row_vals)\n",
    "\n",
    "# Print rs_fxn\n",
    "print(rs_fxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304805c-4d4e-41c2-9a20-882bf1fb7b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Turn list of lists into list of dicts: list_of_dicts\n",
    "list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_lists]\n",
    "\n",
    "# Turn list of dicts into a DataFrame: df\n",
    "df = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059608c-e189-4928-b948-72f3134a3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a connection to the file\n",
    "with open('world_dev_ind.csv') as file:\n",
    "\n",
    "    # Skip the column names\n",
    "    file.readline()\n",
    "\n",
    "    # Initialize an empty dictionary: counts_dict\n",
    "    counts_dict = {}\n",
    "\n",
    "    # Process only the first 1000 rows\n",
    "    for j in range(1000):\n",
    "\n",
    "        # Split the current line into a list: line\n",
    "        line = file.readline().split(',')\n",
    "\n",
    "        # Get the value for the first column: first_col\n",
    "        first_col = line[0]\n",
    "\n",
    "        # If the column value is in the dict, increment its value\n",
    "        if first_col in counts_dict.keys():\n",
    "            counts_dict[first_col] += 1\n",
    "\n",
    "        # Else, add to the dict and set value to 1\n",
    "        else:\n",
    "            counts_dict[first_col] = 1\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253efbc4-aa94-4f1a-b786-fb7d007c3c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define read_large_file()\n",
    "def read_large_file(file_object):\n",
    "    \"\"\"A generator function to read a large file lazily.\"\"\"\n",
    "\n",
    "    # Loop indefinitely until the end of the file\n",
    "    while True:\n",
    "\n",
    "        # Read a line from the file: data\n",
    "        data = file_object.readline()\n",
    "\n",
    "        # Break if this is the end of the file\n",
    "        if not data:\n",
    "            break\n",
    "\n",
    "        # Yield the line of data\n",
    "        yield data\n",
    "\n",
    "# Open a connection to the file\n",
    "with open('world_dev_ind.csv') as file:\n",
    "\n",
    "    # Create a generator object for the file: gen_file\n",
    "    gen_file = read_large_file(file)\n",
    "\n",
    "    # Print the first three lines of the file\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e7b45-b47c-4b12-ade0-d10dfdf8d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary: counts_dict\n",
    "counts_dict = {}\n",
    "\n",
    "# Open a connection to the file\n",
    "with open('world_dev_ind.csv') as file:\n",
    "\n",
    "    # Iterate over the generator from read_large_file()\n",
    "    for line in read_large_file(file):\n",
    "\n",
    "        row = line.split(',')\n",
    "        first_col = row[0]\n",
    "\n",
    "        if first_col in counts_dict.keys():\n",
    "            counts_dict[first_col] += 1\n",
    "        else:\n",
    "            counts_dict[first_col] = 1\n",
    "\n",
    "# Print            \n",
    "print(counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ec1c5-f102-4780-a555-a62ca90c62f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize reader object: df_reader\n",
    "df_reader = pd.read_csv('ind_pop.csv', chunksize=10)\n",
    "\n",
    "# Print two chunks\n",
    "print(next(df_reader))\n",
    "print(next(df_reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406de9cb-1046-4ece-b33f-3a33df47fc31",
   "metadata": {},
   "source": [
    "\n",
    "                                 CountryName CountryCode                  IndicatorName      IndicatorCode  Year   Value\n",
    "0                                 Arab World         ARB  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  31.285\n",
    "1                     Caribbean small states         CSS  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  31.597\n",
    "2             Central Europe and the Baltics         CEB  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  44.508\n",
    "3    East Asia & Pacific (all income levels)         EAS  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  22.471\n",
    "4      East Asia & Pacific (developing only)         EAP  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  16.918\n",
    "5                                  Euro area         EMU  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  62.097\n",
    "6  Europe & Central Asia (all income levels)         ECS  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  55.379\n",
    "7    Europe & Central Asia (developing only)         ECA  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  38.066\n",
    "8                             European Union         EUU  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  61.213\n",
    "9   Fragile and conflict affected situations         FCS  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  17.892\n",
    "                                      CountryName CountryCode                  IndicatorName      IndicatorCode  Year   Value\n",
    "10         Heavily indebted poor countries (HIPC)         HPC  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  12.236\n",
    "11                                    High income         HIC  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  62.680\n",
    "12                           High income: nonOECD         NOC  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  56.108\n",
    "13                              High income: OECD         OEC  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  64.285\n",
    "14  Latin America & Caribbean (all income levels)         LCN  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  49.285\n",
    "15    Latin America & Caribbean (developing only)         LAC  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  44.863\n",
    "16   Least developed countries: UN classification         LDC  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960   9.616\n",
    "17                            Low & middle income         LMY  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  21.273\n",
    "18                                     Low income         LIC  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  11.498\n",
    "19                            Lower middle income         LMC  Urban population (% of total)  SP.URB.TOTL.IN.ZS  1960  19.811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48764f4-b9a2-4142-b59c-48e89ca3d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize reader object: urb_pop_reader\n",
    "urb_pop_reader = pd.read_csv('ind_pop_data.csv', chunksize=1000)\n",
    "\n",
    "# Get the first DataFrame chunk: df_urb_pop\n",
    "df_urb_pop = next(urb_pop_reader)\n",
    "\n",
    "# Check out the head of the DataFrame\n",
    "print(df_urb_pop.head())\n",
    "\n",
    "# Check out specific country: df_pop_ceb\n",
    "df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
    "\n",
    "# Zip DataFrame columns of interest: pops\n",
    "pops = zip(df_pop_ceb['Total Population'], \n",
    "           df_pop_ceb['Urban population (% of total)'])\n",
    "\n",
    "# Turn zip object into list: pops_list\n",
    "pops_list = list(pops)\n",
    "\n",
    "# Print pops_list\n",
    "print(pops_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78db6be-7093-4064-beba-766e16935a6a",
   "metadata": {},
   "source": [
    "                               CountryName CountryCode  Year  Total Population  Urban population (% of total)\n",
    "0                               Arab World         ARB  1960         9.250e+07                         31.285\n",
    "1                   Caribbean small states         CSS  1960         4.191e+06                         31.597\n",
    "2           Central Europe and the Baltics         CEB  1960         9.140e+07                         44.508\n",
    "3  East Asia & Pacific (all income levels)         EAS  1960         1.042e+09                         22.471\n",
    "4    East Asia & Pacific (developing only)         EAP  1960         8.965e+08                         16.918\n",
    "[(91401583.0, 44.5079211390026), (92237118.0, 45.206665319194), (93014890.0, 45.866564696018), (93845749.0, 46.5340927663649), (94722599.0, 47.2087429803526)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6cb2a-bb4f-4415-b17c-63bd1aa6bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
    "df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
    "\n",
    "# Plot urban population data\n",
    "df_pop_ceb.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b7ab5-ac27-4b9c-9892-568ff9782ed3",
   "metadata": {},
   "source": [
    "In the previous exercises, you've only processed the data from the first DataFrame chunk. \n",
    "### This time, you will aggregate the results over all the DataFrame chunks in the dataset. \n",
    "This basically means you will be processing the entire dataset now. This is neat because you're going to be able to process the entire large dataset by just working on smaller pieces of it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c996c9-8212-4b16-b9ce-0f3944b1c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize reader object: urb_pop_reader\n",
    "urb_pop_reader = pd.read_csv('ind_pop_data.csv', chunksize=1000)\n",
    "\n",
    "# Initialize empty DataFrame: data\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Iterate over each DataFrame chunk\n",
    "for df_urb_pop in urb_pop_reader:\n",
    "\n",
    "    # Check out specific country: df_pop_ceb\n",
    "    df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
    "\n",
    "    # Zip DataFrame columns of interest: pops\n",
    "    pops = zip(df_pop_ceb['Total Population'],\n",
    "                df_pop_ceb['Urban population (% of total)'])\n",
    "\n",
    "    # Turn zip object into list: pops_list\n",
    "    pops_list = list(pops)\n",
    "\n",
    "    # Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
    "    df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
    "    \n",
    "    # Concatenate DataFrame chunk to the end of data: data\n",
    "    data = pd.concat([data, df_pop_ceb])\n",
    "\n",
    "# Plot urban population data\n",
    "data.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f26db-2cff-478e-89e9-cff1df0bd976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plot_pop()\n",
    "def plot_pop(filename, country_code):\n",
    "\n",
    "    # Initialize reader object: urb_pop_reader\n",
    "    urb_pop_reader = pd.read_csv(filename, chunksize=1000)\n",
    "\n",
    "    # Initialize empty DataFrame: data\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over each DataFrame chunk\n",
    "    for df_urb_pop in urb_pop_reader:\n",
    "        # Check out specific country: df_pop_ceb\n",
    "        df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == country_code]\n",
    "\n",
    "        # Zip DataFrame columns of interest: pops\n",
    "        pops = zip(df_pop_ceb['Total Population'],\n",
    "                    df_pop_ceb['Urban population (% of total)'])\n",
    "\n",
    "        # Turn zip object into list: pops_list\n",
    "        pops_list = list(pops)\n",
    "\n",
    "        # Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
    "        df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
    "        \n",
    "        # Concatenate DataFrame chunk to the end of data: data\n",
    "        data = pd.concat([data, df_pop_ceb])\n",
    "\n",
    "    # Plot urban population data\n",
    "    data.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
    "    plt.show()\n",
    "\n",
    "# Set the filename: fn\n",
    "fn = 'ind_pop_data.csv'\n",
    "\n",
    "# Call plot_pop for country code 'CEB'\n",
    "plot_pop(fn, 'CEB')\n",
    "\n",
    "# Call plot_pop for country code 'ARB'\n",
    "plot_pop(fn, 'ARB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
